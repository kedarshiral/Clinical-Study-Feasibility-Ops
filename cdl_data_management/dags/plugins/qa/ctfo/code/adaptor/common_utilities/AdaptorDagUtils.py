"""This module fetches batch status."""
# !/usr/bin/python3
# -*- coding: utf-8 -*-
import socket
import json
import copy
import logging
import traceback
import subprocess
import random
import os
import sys
import datetime as dt
import time
from urllib.parse import urlparse
import boto3
import pandas
import pyarrow.parquet as pq
import ast
import base64


service_directory_path = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(1, service_directory_path)
code_dir_path = os.path.abspath(os.path.join(service_directory_path, "../"))
sys.path.insert(1, code_dir_path)

logger = logging.getLogger('__name__')
hndlr = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
hndlr.setFormatter(formatter)

import CommonConstants
from CommonUtils import CommonUtils
# from ExecutionContext import ExecutionContext
# from SshEmrUtility import SshEmrUtility
from SystemManagerUtility import SystemManagerUtility
from CustomS3Utility import CustomS3Utility
from DILogSetup import get_logger
from EmrManagerUtility import EmrManagerUtility
from ExecutionContext import ExecutionContext
from MySQLConnectionManager import MySQLConnectionManager


def call_OrganizationDataPrep():
    """This method calls the  call_OrganizationDataPrep  code"""
    """This method calls call_OrganizationDataPrep"""
    APPLICATION_CONFIG_FILE = "application_config.json"
    print("os.getcwd()", os.getcwd())
    application_conf = CommonConstants.AIRFLOW_CODE_PATH + "/adaptor/common_utilities/" + APPLICATION_CONFIG_FILE
    configuration = json.load(open(application_conf))
    audit_db = configuration["adapter_details"]["generic_config"]["mysql_db"]
    print("audit_db :",audit_db)
    query_str = (
        "select cluster_id from {audit_db}.{log_data_acquisition_smry_table} "
        " where source_name = 'organization' and payload_id ='5' and adapter_id=5 and status='Running' order by start_time desc limit 1"
    )
    output_query = query_str.format(audit_db=audit_db,
                                    log_data_acquisition_smry_table=CommonConstants.LOG_DATA_ACQUISITION_SMRY_TABLE
                                    )
    logging.info("Query to select cluster id from the log table: %s", str(output_query))
    response_clusterid = MySQLConnectionManager().execute_query_mysql(output_query, False)

    # DJ
    cluster_id_response = response_clusterid[0]["cluster_id"]
    logging.info("Query output cluster id: %s", str(cluster_id_response))

    cluster_id = cluster_id_response
    logger.info("================Executing job in Spark client mode================")
    conf_value="  "
    logger.info("cd /usr/local/airflow/dags/plugins/qa/ctfo/code/adaptor/organizationtrials " + "; sh OrganizationDataPrepAdapter.sh "
                + str(conf_value))

    command_to_execute = "cd /usr/local/airflow/dags/plugins/qa/ctfo/code/adaptor/organizationtrials; " \
                         + " sh OrganizationDataPrepAdapter.sh " \
                         + '"' + str(conf_value) + '"'
    print("command_to_execute ",command_to_execute)
    output = SystemManagerUtility().execute_command(cluster_id, command_to_execute)
    logging.info("Output generated by OrganizationDataPrepAdapter task - " + str(output))

